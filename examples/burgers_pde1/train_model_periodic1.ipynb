{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25c34cc-0ce1-411d-8546-955a49476be5",
   "metadata": {},
   "source": [
    "### GD-VAE: Viscous Burgers Non-Linear PDE: Periodic Case\n",
    "[http://atzberger.org](http://atzberger.org)\n",
    "\n",
    "### Overview\n",
    "\n",
    "Trains model for the dynamics of the viscous burgers PDE $u_t = -uu_x + \\nu u_{xx}$ in the case of periodic boundary conditions.  By adjusting parameters the latent space can be taken to be a standard euclidean space or a manifold latent space.\n",
    "\n",
    "For more information see the documentation and GD-VAEs paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59700d0-20bd-4117-aa35-a342bf4f6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general packages\n",
    "import sys,os,pickle,time,argparse,numpy as np;\n",
    "import torch,torch.nn;\n",
    "\n",
    "# GD-VAE packages\n",
    "import gd_vae_pytorch as gd_vae,gd_vae_pytorch.vae,gd_vae_pytorch.geo_map,gd_vae_pytorch.utils;\n",
    "\n",
    "# local packages\n",
    "import pkg,pkg.model_utils as model_utils,pkg.datasets as datasets;\n",
    "\n",
    "# script name without extension\n",
    "script_base_name = 'train_model_periodic1';\n",
    "\n",
    "# de-reference for later convenience\n",
    "PointCloudPeriodicProjWithTime = model_utils.PointCloudPeriodicProjWithTime;\n",
    "analytic_periodic_proj_with_time = model_utils.analytic_periodic_proj_with_time;\n",
    "\n",
    "PeriodicDataset = datasets.PeriodicDataset; \n",
    "\n",
    "Encoder_Fully_Connected = model_utils.Encoder_Fully_Connected;\n",
    "Decoder_Fully_Connected = model_utils.Decoder_Fully_Connected;\n",
    "\n",
    "dyvae_loss = gd_vae.vae.dyvae_loss;\n",
    "mse_loss = torch.nn.MSELoss();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a543b65-1a39-46ed-9a88-e0a84852cd67",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7af333-5d7e-4a12-a9c1-5826b1384bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters \n",
    "flag_load_from_file = False;\n",
    "if flag_load_from_file:\n",
    "  param_filename='./script_data/study_0001/VAE__Analytic_Projection_00000/params.pickle';\n",
    "\n",
    "  print(\"\");print(\"param_filename = \" + str(param_filename));print(\"\");\n",
    "  with open(param_filename, 'rb') as param_file:\n",
    "    run_params = pickle.load(param_file);\n",
    "    \n",
    "else:        \n",
    "    #Define and save parameters to file\n",
    "    default_params = {\n",
    "      'input_dim' : 100,\n",
    "      'latent_dim' : 3,\n",
    "      'time_step' : 0.25,\n",
    "      'train_num_samples' : int(1e4),\n",
    "      'test_num_samples' : int(1e4),\n",
    "      'noise' : 0.02,\n",
    "      'batch_size' : 100,\n",
    "      'gamma' : 1, # reconstruction regularization\n",
    "      'num_epochs' : int(4e2),\n",
    "      'learning_rate' : 1e-4,\n",
    "      'm1_mc' : 1, # for monte carlo estimates\n",
    "      'beta' : 1e-4,\n",
    "      'latent_prior_std_dev' : 1.0,\n",
    "      'use_analytic_projection_map' : True,\n",
    "      'use_point_cloud_projection_map' : False,\n",
    "      'mse_loss' : False,\n",
    "      'encoder_size': [100, 400, 400],\n",
    "      'decoder_size': [400, 400, 100], \n",
    "      'save_every_n_epoch': 100,  \n",
    "      'num_points_in_cloud': None \n",
    "    }\n",
    "    \n",
    "    run_name_base = 'VAE__Analytic_Projection';     \n",
    "    run_params = default_params;\n",
    "    \n",
    "    if run_name_base == 'VAE__Analytic_Projection':\n",
    "        pass;\n",
    "    elif run_name_base == 'VAE__Point_Cloud_Projection':\n",
    "        run_params['use_analytic_projection_map'] = False;\n",
    "        run_params['use_point_cloud_projection_map'] = True;\n",
    "        run_params['num_points_in_cloud'] = 100;\n",
    "    elif run_name_base == 'VAE__No_Projection':\n",
    "        run_params['use_analytic_projection_map'] = False;\n",
    "    elif run_name_base == 'AE__Analytic_Projection':\n",
    "        run_params['mse_loss'] = True;\n",
    "    elif run_name_base == 'AE__No_Projection':\n",
    "        run_params['use_analytic_projection_map'] = False;\n",
    "        run_params['mse_loss'] = True;\n",
    "    elif run_name_base == 'VAE__2d':\n",
    "        run_params['use_analytic_projection_map'] = False;\n",
    "        run_params['latent_dim'] = 2;\n",
    "    elif run_name_base == 'VAE__10d':\n",
    "        run_params['use_analytic_projection_map'] = False;\n",
    "        run_params['latent_dim'] = 10;\n",
    "    else:\n",
    "        raise ValueError(f'Run Name {run_name_base} Not Recognized');    \n",
    "\n",
    "base_dir = os.path.join('output',script_base_name,run_name_base);\n",
    "print(\"base_dir = \" + base_dir);\n",
    "gd_vae.utils.create_dir(base_dir);\n",
    "\n",
    "param_filename = os.path.join(base_dir,'params.pickle');\n",
    "print(\"\");\n",
    "print(\"param_filename = \" + param_filename);\n",
    "f = open(param_filename,'wb'); pickle.dump(run_params,f); f.close();\n",
    "\n",
    "run_params['data_folder_path'] = os.path.join(base_dir,'data');\n",
    "\n",
    "data_dir = run_params['data_folder_path'];\n",
    "print(\"\");\n",
    "print(\"data_dir = \" + data_dir);\n",
    "gd_vae.utils.create_dir(data_dir);\n",
    "\n",
    "print(\"\");\n",
    "print(\"run_params.keys() = \" + str(run_params.keys()));\n",
    "\n",
    "# passed into VAE loss function\n",
    "extra_params = {};\n",
    "extra_params['beta'] = run_params['beta']; # beta value in beta-VAE\n",
    "extra_params['gamma'] = run_params['gamma']; # gamma for reconstruction term as regularization\n",
    "extra_params['num_monte_carlo_samples'] = run_params['m1_mc']; \n",
    "extra_params['device'] = None;\n",
    "extra_params['latent_prior_std_dev'] = torch.Tensor([run_params['latent_prior_std_dev']]);\n",
    "extra_params['mse_loss'] = mse_loss;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a22e6-32e1-46e6-bddd-5926e3df0ba4",
   "metadata": {},
   "source": [
    "### Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53967e9-2536-4097-8e47-a35efff2cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = torch.linspace(0,1.0,run_params['input_dim']+1)[0:-1];\n",
    "train_data_params = {'time_step':run_params['time_step'],'noise':run_params['noise']};\n",
    "train_dataset = PeriodicDataset(xi, run_params['train_num_samples'], train_data_params);\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=run_params['batch_size'],shuffle=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70b02f-e853-4e11-b41b-5e6e817c931a",
   "metadata": {},
   "source": [
    "### Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3698a53e-715f-4f5c-9234-bce6ed903605",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = {};\n",
    "encoder = Encoder_Fully_Connected(run_params['encoder_size'], run_params['latent_dim']);\n",
    "if (not run_params['use_analytic_projection_map']) and (not run_params['use_point_cloud_projection_map']):\n",
    "  phi['model_mu'] = encoder.mean;\n",
    "elif run_params['use_analytic_projection_map']:\n",
    "  phi['model_mu'] = lambda input : analytic_periodic_proj_with_time(encoder.mean(input));\n",
    "elif run_params['use_point_cloud_projection_map']:\n",
    "  point_cloud_periodic_proj_with_time = PointCloudPeriodicProjWithTime(run_params['num_points_in_cloud']);\n",
    "  phi['model_mu'] = lambda input : point_cloud_periodic_proj_with_time(encoder.mean(input));\n",
    "phi['model_log_sigma_sq'] = encoder.log_variance;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e1044-911d-497a-93ce-2c1129d16383",
   "metadata": {},
   "source": [
    "### Decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867148d3-1c51-494f-a21c-d3eb61a1dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder_Fully_Connected(run_params['decoder_size'], run_params['latent_dim'])\n",
    "theta = {'model_mu' : decoder.mean}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e098f-de7e-4dee-aa87-8ccc9a1bc4da",
   "metadata": {},
   "source": [
    "### Latent map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d14a41-0826-4563-a60a-0f652043a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_map = model_utils.latent_map_forward_in_time; # evolution map forward in time\n",
    "latent_map_params = {'time_step':run_params['time_step']};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ee2a5-972e-4516-ac65-3363d5b25fcb",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c2a1e-8ac3-4a9b-963c-ddc5b37e0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_opt = []; # list of parameters to be optimized\n",
    "params_to_opt += list(encoder.mean.parameters());\n",
    "params_to_opt += list(encoder.log_variance.parameters());\n",
    "params_to_opt += list(decoder.mean.parameters());\n",
    "optimizer = torch.optim.Adam(params_to_opt, lr=run_params['learning_rate']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e07b3-a9e9-4378-a7ae-092201702434",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dd83b-9e59-4bad-bb28-fe01f8142e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the models:\");\n",
    "num_steps = len(train_loader);\n",
    "encoder.save_encoder_model(data_dir, epoch=0); decoder.save_decoder_model(data_dir, epoch=0);\n",
    "\n",
    "print('.'*80);  \n",
    "for epoch in range(run_params['num_epochs']):\n",
    "  epoch_start_time = time.time();\n",
    "\n",
    "  for i, (input,target) in enumerate(train_loader):\n",
    "\n",
    "    # calculate loss funtion\n",
    "    if not run_params['mse_loss']:\n",
    "      loss = dyvae_loss(phi['model_mu'], phi['model_log_sigma_sq'], theta['model_mu'], \n",
    "                        latent_map, latent_map_params, input, target, **extra_params);\n",
    "    elif run_params['mse_loss']:\n",
    "      latent = phi['model_mu'](input);\n",
    "      latent_ev = latent_map(latent);\n",
    "      reconstructed = theta['model_mu'](latent);\n",
    "      predicted = theta['model_mu'](latent_ev);\n",
    "      loss = mse_loss(predicted, target) + run_params['gamma']*mse_loss(reconstructed, input);\n",
    "\n",
    "    # perform gradient descent\n",
    "    optimizer.zero_grad(); loss.backward(); optimizer.step();\n",
    "\n",
    "    # report progress\n",
    "    if ((i + 1) % 100) == 0 or i == 0:        \n",
    "      msg = 'epoch: [%d/%d]; '%(epoch+1,run_params['num_epochs']);\n",
    "      msg += 'batch_step = [%d/%d]; '%(i + 1,num_steps);\n",
    "      msg += 'loss: %.3e; '%(loss.item());\n",
    "      print(msg);\n",
    "\n",
    "  # epoch finished      \n",
    "  print(\"time taken: %.1e s\"%(time.time()-epoch_start_time));  \n",
    "  print('.'*80);  \n",
    "\n",
    "  if (epoch+1)%run_params['save_every_n_epoch'] == 0:\n",
    "    encoder.save_encoder_model(data_dir, epoch+1);\n",
    "    decoder.save_decoder_model(data_dir, epoch+1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663e197-6ccd-432d-8a3d-7da90cd6226e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch39_1_11_0]",
   "language": "python",
   "name": "conda-env-pytorch39_1_11_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
